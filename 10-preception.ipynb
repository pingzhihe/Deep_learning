{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 感知机(preception)\n",
    "* 感知机是一个二分类模型，是最早的AI模型之一\n",
    "* 它的求解算法等价于使用批量大小为1的梯度下降\n",
    "* 它不能拟合XOR函数，导致了第一次AI寒冬\n",
    "\n",
    "## 多层感知机\n",
    "* 多层感知机使用隐藏层和激活函数来得到非线性曲线\n",
    "* 常用函数是Sigmoid, Tanh, ReLU等\n",
    "* 使用Softmax 来处理多类分类\n",
    "* 超参数为隐藏层数, 和各个隐藏层大小\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对图像进行分析，这里图形为28*28的灰度图，所以输入层为28*28=784。所有图像共分为10个类别。\n",
    "我们可以将每个图像视为具有784个输入特征和10个类别的简单分类数据集。\n",
    "首相我们将实现一个具有*单隐藏层*的多层感知机，它包含256个隐藏单元。层数和隐藏单元数是超参数，可以调整。\n",
    "通常，我们选择2的若干幂作为层的宽度，因为内存在硬件中的分配和寻址方式，这么做往往更高效。\n",
    "\n",
    "我们用几个张量表示我们的参数。对于每一次我们都需要记录一个权重矩阵和一个偏置向量。跟以前一样，我们要为损失关于这些参数的梯度分配内存。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "\n",
    "num_inputs, num_outputs, num_hiddens = 784, 10, 256\n",
    "\n",
    "W1 = nn.Parameter(torch.randn(num_inputs, num_hiddens, requires_grad=True) * 0.01)\n",
    "b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True))\n",
    "\n",
    "W2 = nn.Parameter(torch.randn(num_hiddens, num_outputs, requires_grad=True) * 0.01)\n",
    "b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True))\n",
    "\n",
    "params = [W1, b1, W2, b2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用ReLU 激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    a = torch.zeros_like(X)\n",
    "    return torch.max(X, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为我们忽略了空间结构，所以我们使用reshape将每个二维图像转换成一个长度为num_inputs的向量。然后我们实现MLP的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    X = X.reshape((-1, num_inputs))\n",
    "    H = relu(X @ W1 + b1)\n",
    "    return (H @ W2 + b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs, lr = 10, 0.1\n",
    "updater = torch.optim.SGD(params, lr=lr)\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.predict_ch3(net, test_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "charles",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
